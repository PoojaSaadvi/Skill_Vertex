{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade9f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12279a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee4286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af61ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d1400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df, column, value):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[column].fillna(value=value,inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "train_data = fill_missing(train_data, \"education\", \"others\")\n",
    "test_data = fill_missing(test_data, \"education\", \"others\")\n",
    "\n",
    "train_data = fill_missing(train_data, \"previous_year_rating\", 0.0)\n",
    "test_data = fill_missing(test_data, \"previous_year_rating\", 0.0)\n",
    "\n",
    "train_data.education.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.department.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.recruitment_channel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(df, column_list):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[column_list] = df_copy[column_list].apply(lambda x: x.astype('category'))\n",
    "    return df_copy\n",
    "\n",
    "train_data = convert_to_category(train_data, ['department','region','education',\n",
    "                                              'gender','recruitment_channel'])\n",
    "test_data = convert_to_category(test_data, ['department','region','education',\n",
    "                                            'gender','recruitment_channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = bool(train_data.duplicated(subset = 'employee_id').any())\n",
    "\n",
    "if condition:\n",
    "    print('There are duplicate employee IDs')\n",
    "else:\n",
    "    print('No duplicate employee IDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.is_promoted.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21610489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns='employee_id',inplace=True)  \n",
    "test_data.drop(columns='employee_id',inplace=True)  \n",
    "\n",
    "train_data.hist(bins=20, figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bar(column_name):\n",
    "\n",
    "    promo_by_group = pd.crosstab(index=train_data['is_promoted'],columns = train_data[column_name], normalize = 'columns')\n",
    "    promo_by_group = promo_by_group.apply(lambda x: round(x,2))\n",
    "    \n",
    "    labels = promo_by_group.columns\n",
    "    list1 = promo_by_group.iloc[0].to_list()\n",
    "    list2 = promo_by_group.iloc[1].to_list()\n",
    "    \n",
    "    list1_name = \"Not promoted\"\n",
    "    list2_name = \"Promoted\"\n",
    "    title = f\"Promotion by {column_name}\"\n",
    "    xlabel = column_name\n",
    "    ylabel = \"Promotion percentage\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    bar_width = 0.5\n",
    "    \n",
    "    ax1 = ax.bar(labels,list1, bar_width, label = list1_name)\n",
    "    ax2 = ax.bar(labels,list2, bar_width, bottom = list1, label = list2_name)\n",
    "\n",
    "    ax.set_title(title, fontweight = \"bold\")\n",
    "    ax.set_xlabel(xlabel, fontweight = \"bold\")\n",
    "    ax.set_ylabel(ylabel, fontweight = \"bold\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    \n",
    "    plt.xticks(list(range(len(labels))), labels,rotation=90)\n",
    "    plt.yticks(fontsize=9)\n",
    "\n",
    "    for r1, r2 in zip(ax1, ax2):\n",
    "        h1 = r1.get_height()\n",
    "        h2 = r2.get_height()\n",
    "        plt.text(r1.get_x() + r1.get_width() / 2., h1 / 2., f\"{h1:.0%}\", ha=\"center\", va=\"center\", color=\"white\", fontsize=9, fontweight=\"bold\")\n",
    "        plt.text(r2.get_x() + r2.get_width() / 2., h1 + h2 / 2., f\"{h2:.0%}\", ha=\"center\", va=\"center\", color=\"white\", fontsize=9, fontweight=\"bold\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5255a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar('department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35619ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar('education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584a5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c05d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stacked_bar('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_to_group(df):\n",
    "    df_copy = df.copy()\n",
    "    bins = range(20,61,5)    # every 5 years as a bin\n",
    "    labels = list(range(len(bins)-1))\n",
    "    df_copy['age_group'] = pd.cut(df_copy['age'],bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    df_copy.drop(columns=[\"age\"], inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "train_data = convert_age_to_group(train_data)\n",
    "test_data = convert_age_to_group(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def convert_to_numerical(df_train, df_test):\n",
    "    df_train_copy = df_train.copy()\n",
    "    df_test_copy = df_test.copy()\n",
    "    \n",
    "    for i in [\"department\", \"region\", \"education\", \"gender\", \"recruitment_channel\", \"age_group\"]:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df_train_copy.loc[:, i])\n",
    "        df_train_copy.loc[:, i] = le.transform(df_train_copy.loc[:, i])\n",
    "        df_test_copy.loc[:, i] = le.transform(df_test_copy.loc[:, i])\n",
    "    \n",
    "    return df_train_copy, df_test_copy\n",
    "\n",
    "train_data, test_data = convert_to_numerical(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67834d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['is_promoted'])\n",
    "y = train_data['is_promoted']\n",
    "\n",
    "X_test = test_data.copy()\n",
    "\n",
    "feature_cols = X.columns.tolist() \n",
    "\n",
    "num_cols = ['no_of_trainings', 'previous_year_rating', 'length_of_service','KPIs_met >80%',\n",
    "            'awards_won?', 'avg_training_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109a7be",
   "metadata": {},
   "source": [
    "3. Split Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c18117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def data_split(X, y, imbalance = False):\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3,shuffle=True,\n",
    "                                                                    stratify=y, random_state=42)\n",
    "    \n",
    "    if imbalance:\n",
    "        sm = SMOTE(random_state = 42)\n",
    "        X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n",
    "    \n",
    "    return X_train, X_validation, y_train, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c81de",
   "metadata": {},
   "source": [
    "4. Rescale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f530db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standard_scaler(X_train, X_validation, X_test,  numerical_cols):\n",
    "    \n",
    "    X_train_std = X_train.copy()\n",
    "    X_validation_std = X_validation.copy()\n",
    "    X_test_std = X_test.copy()\n",
    "    \n",
    "    for i in numerical_cols:\n",
    "        scl = StandardScaler().fit(X_train_std[[i]])     \n",
    "        X_train_std[i] = scl.transform(X_train_std[[i]]) \n",
    "        X_validation_std[i] = scl.transform(X_validation_std[[i]])   \n",
    "        X_test_std[i] = scl.transform(X_test_std[[i]])   \n",
    "\n",
    "    return X_train_std, X_validation_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029f41a8",
   "metadata": {},
   "source": [
    "Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "def run_models(X, y, X_test, num_cols, models):\n",
    "    \n",
    "    model_result = []\n",
    "\n",
    "    for imbalance in [True, False]:\n",
    "        X_train, X_validation, y_train, y_validation = data_split(X, y, imbalance = imbalance)\n",
    "        X_train_std, X_validation_std, X_test_std = standard_scaler(X_train, X_validation, X_test\n",
    "                                                                    , numerical_cols = num_cols)\n",
    "       \n",
    "        for model_name, model in models.items():\n",
    "            model.fit(X_train_std, y_train)\n",
    "            joblib.dump(model, f\"{model_name}.pkl\")  \n",
    "            scores = cross_val_score(model, X_train_std, y_train, scoring =\"roc_auc\", cv = 5)\n",
    "            roc_auc = np.mean(scores)\n",
    "\n",
    "            model_result.append([model_name, imbalance,  roc_auc]) \n",
    "    df = pd.DataFrame(model_result, columns = [\"Model\", \"SMOTE\" , \"ROC_AUC Score\"])  \n",
    "    df.to_csv(\"model_initial.csv\", index=None)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9008179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\"Logistic Regression\":LogisticRegression(random_state=42), \n",
    "              \"Random Forest\":RandomForestClassifier(random_state=42), \n",
    "              \"XGBoost\":  XGBClassifier(random_state=42)}\n",
    "\n",
    "run_models(X, y, X_test, num_cols, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1181fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = data_split(X, y, imbalance = True)\n",
    "\n",
    "X_train_std, X_validation_std, X_test_std = standard_scaler(X_train, X_validation, X_test, numerical_cols = num_cols)\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,random_state=42)\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "lr_best = RandomizedSearchCV(logistic, distributions, random_state=42)\n",
    "\n",
    "lr_best= lr_best.fit(X_train_std, y_train)   \n",
    "\n",
    "print(lr_best.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb570882",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_best,\"logreg_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tuned = cross_val_score(lr_best, X_validation_std, y_validation, scoring = \"roc_auc\", cv = 5)\n",
    "roc_auc_lr_best = np.mean(scores_tuned)\n",
    "\n",
    "joblib.dump(roc_auc_lr_best,\"logreg_ROC_AUC_tuned.pkl\") \n",
    "\n",
    "print(f'ROC_AUC score after tuning parameters:{roc_auc_lr_best:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = data_split(X, y, imbalance = True)\n",
    "param_grid = {\n",
    "    'max_depth': [60, 90, 110],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_best = GridSearchCV(estimator = clf_rf, param_grid = param_grid,    \n",
    "                          cv = 3, n_jobs = -1, verbose = 1)\n",
    "\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_best,\"clf_rf_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = data_split(X, y, imbalance = True)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [50,60,70],\n",
    "    'min_samples_leaf': [2,3],\n",
    "    'min_samples_split': [6,7,8],\n",
    "    'n_estimators': [200,300,400]\n",
    "}\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_best1 = GridSearchCV(estimator = clf_rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 1)\n",
    "\n",
    "rf_best1.fit(X_train, y_train)\n",
    "rf_best1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b563c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tuned = cross_val_score(rf_best1, X_validation, y_validation, scoring = \"roc_auc\", cv = 5)\n",
    "roc_auc_rf_best = np.mean(scores_tuned)\n",
    "\n",
    "joblib.dump(roc_auc_rf_best,\"rf_ROC_AUC_tuned.pkl\") \n",
    "\n",
    "print(f'ROC_AUC score after tuning parameters:{roc_auc_rf_best:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "n_estimators = np.arange(200,1000,200)\n",
    "\n",
    "gamma = np.arange(0.1,0.6,0.1)\n",
    "learning_rate = np.arange(0.1,0.6,0.1)\n",
    "\n",
    "max_depth = list(range(3,8,1))\n",
    "\n",
    "subsample = np.arange(0.5,0.9,0.1)\n",
    "colsample_bytree = np.arange(0.5,0.9,0.1)\n",
    "\n",
    "scale_pos_weight = [1,3.5]\n",
    "random_grid_xgb = {'n_estimators': n_estimators,\n",
    "                   'gamma': gamma,\n",
    "                   'learning_rate':learning_rate,\n",
    "                   'max_depth': max_depth,\n",
    "                   'subsample':subsample,\n",
    "                   'colsample_bytree':colsample_bytree,\n",
    "                   'scale_pos_weight':scale_pos_weight\n",
    "                  }\n",
    "pprint(random_grid_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = data_split(X, y, imbalance = True)\n",
    "xgboost = XGBClassifier()\n",
    "xgb_random = RandomizedSearchCV(estimator = xgboost, \n",
    "                                param_distributions = random_grid_xgb, \n",
    "                                n_iter = 100, \n",
    "                                cv = 3, \n",
    "                                verbose=1, \n",
    "                                random_state=42, \n",
    "                                n_jobs = -1,\n",
    "                                scoring ='roc_auc')\n",
    "\n",
    "\n",
    "xgb_random.fit(X_train, y_train)   \n",
    "xgb_random.best_params_, xgb_random.best_score_\n",
    "\n",
    "print(xgb_random.best_params_,xgb_random.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96728d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_random,\"xgb_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42922946",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_tuned = cross_val_score(xgb_random, X_validation, y_validation, scoring = \"roc_auc\", cv = 5)\n",
    "roc_auc_xgb_best = np.mean(scores_tuned)\n",
    "\n",
    "joblib.dump(roc_auc_xgb_best,\"xgb_ROC_AUC_tuned.pkl\") \n",
    "\n",
    "print(f'ROC_AUC score after tuning parameters:{roc_auc_xgb_best:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_pre_rec_f1(model_name, model,X_validation,y_validation):\n",
    "    y_pred = model.predict(X_validation)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_validation, y_pred).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return [model_name, precision, recall, F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = get_pre_rec_f1(\"Logistic\", lr_best, X_validation_std, y_validation)\n",
    "\n",
    "col_2 = get_pre_rec_f1(\"Random Forest\",  rf_best1, X_validation, y_validation)\n",
    "\n",
    "col_3 = get_pre_rec_f1(\"XGBoost\", xgb_random, X_validation, y_validation)\n",
    "\n",
    "result = []\n",
    "result.append(col_1)\n",
    "result.append(col_2)\n",
    "result.append(col_3)\n",
    "\n",
    "pd.DataFrame(result, columns = [\"Model\", \"Precision\", \"Recall\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,5))\n",
    "\n",
    "plot_roc_curve(lr_best, X_validation_std, y_validation,ax=ax, color=\"blue\",label='Logistic Regression')\n",
    "plot_roc_curve(rf_best1, X_validation, y_validation,ax=ax, color=\"green\",label='Random Forest')\n",
    "plot_roc_curve(xgb_random, X_validation, y_validation,ax=ax, color=\"red\",label='XGBoost')\n",
    "\n",
    "plt.title('ROC/AUC of 3 models')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc8ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('F:/test.csv')\n",
    "\n",
    "y_prediction = xgb_random.predict(X_test)\n",
    "result_submission = pd.DataFrame({\"employee_id\" : test_data.employee_id, \"is_promoted\" : y_prediction})\n",
    "result_submission.to_csv(\"F:/submission.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
